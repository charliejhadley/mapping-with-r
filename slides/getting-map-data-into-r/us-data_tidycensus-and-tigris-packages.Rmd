---
title: "US data: {tidycensus} and {tigris} packages"
output:
  xaringan::moon_reader:
    css: ["style.css", "default"]
    lib_dir: libs
    df_print: paged
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: 16:9
editor_options: 
  chunk_output_type: console
---

```{r child = "setup.Rmd"}
```

```{r, include=FALSE, eval=TRUE}
library("sf")
library("tidyverse")
library("rnaturalearthdata")
library("mapview")
library("patchwork")
library("leaflet")
library("leaflet.extras")
library("readxl")
library("janitor")
library("stars")
library("emo")
library("tigris")
library("tidycensus")
```

class: center, middle, dk-section-title
background-image:url("images/us-maps.jpg")
background-size: 100%

# US data: {tidycensus} and {tigris} packages

???

R has a very international and diverse community and this course is designed for folks from anywhere who studying any and every region. In this video we're specifically looking at how to obtain data about the United States of America, in the very next video we'll look at how to obtain administrative regions and other geospatial data for non-US regions.

I think it's worthwhile having a specific video targeted at the USA because there are two very powerful packages for working with US geospatial datasets: tidycensus and tigris. But. If you're never going to need maps of the USA feel free to move on to the next video.

---

## TIGER & {tigris}

.pull-left[

The US Census Bureau is responsible for maintaining shapefiles and other geospatial datasets for contiguous US and its territories.

The collated dataset is called TIGER (Topologically Integrated Geographic Encoding and Referencing).

The `{tigris}` package provides programmatic access to **current and historic** components of TIGER.

]

.pull-right[
<br>
<center>
<img src='images/tigris_sticker.png' width="250px"/>
</center>

]

???

In the US the Census Bureau is responisble for collecting and maintaining shapefiles and other geospatial datasets for the contiguous US and its territories.

Collectively this dataset is called TIGER... originally it was designed to faciliate the collection of census data, but it now contains a multitude of datasets - some of which we'll see during this video.

The {tigris} package provides programmatic access to both current and historic components of TIGER.

---

## {tigris}

- The `{tigris}` doesn't *contain* any datasets, they must be **downloaded** after the package is loaded.

- Think carefully about how detailed a shapefile you require - for many functions the default `{sf}` objects are ***large***.
  - Make sure to check for the `cb` argument!



.pull-left[

The `{tigris}` doesn't *contain* any datasets, they must be **downloaded** after the package is loaded.

Think carefully about how detailed a shapefile you require - for many functions the default `{sf}` objects are ***large***.

]

.pull-right[
<br>
<center>
<img src='images/tigris_sticker.png' width="250px"/>
</center>

]

???

There's two things about the tigris package you need to know:

- firstly, it doesn't actually contain any shapefiles inside of the package - instead they must be downloaded after the package is loaded... which means you'll need internet access to use this package... but I'll show you a nice workflow you can use to store a local copy of the shapefiles.

- secondly, it's important to think how detailed a shapefile you require - for many of the functions the default sf objects are large and may be frustrating to use... this often comes down to checking if a function has a `cb` argument... but we'll need to switch over to RStudio to  really understand what that means.

so, let's do that. I'm going to create a new project for this video

---

## (RStudio Coding Slide)

???


so, let's do that. I'm going to create a new project for this video call it us-data_tigris-and-tidycensus

Now the project is loaded I'm going to load up the packages we'll need:

library("tigris") to obtain the shapefiles - we're going to ignore the message here, but I've explained what it means in the "Learn more" section for this video.

library("sf") for manipulating the objects

library("tidyverse") for tidyvere things

library("mapview") so we can see what we're working with!

Let's obtain the congressional_districts() of the US first.

[[Use the autocompletion to find the function]]

Now let's take a look at the docs for the function - and yep, here's the cb argument I mentioned and note that by default it's FALSE.

We can also find this argument in the following pages:

states... and tracts... there's a few more but this is enough to make my point!

I want to show you that changing the resolution argument of the functions doesn't change anything unless we also change cb to TRUE!

To show that, let's get the default congressional districts shapefile and then plot it

us_cd_default <- congressional_districts()

us_cd_default %>%
  mapview()

It takes a little bit of time to generate this map, because there's a lot of detail in it! We're using a scale of 1:500k

Let's try and get the lower resolution shapefile by setting the resolution to 1:20million

us_cd_20m <- congressional_districts(resolution = "20m")

us_cd_20m %>%
  mapview()
  
This still looks the same! That's because we haven't changed cb = TRUE

congressional_districts(resolution = "20m", cb = TRUE) %>%
  mapview()
  

---

### tigris::________________(cb = TRUE)

It's a common mistake to forget to set `cb = TRUE`

.pull-left[
```{r, eval=TRUE,out.height='250px'}
states(resolution = "500k") %>%
  filter(NAME == "Washington") %>%
  mapview()
```
]

.pull-right[
```{r, eval=TRUE,out.height='250px'}
states(resolution = "500k", cb = TRUE) %>%
  filter(NAME == "Washington") %>%
  mapview()
```
]

???

Let's take a look at a more concrete example! Here I've extracted the shapefile for Washington, and with cb = TRUE we can see the fjords but with the default argument Washinton has a much less interesting shape!

---

## (RStudio Coding Slide)

???

To finish off with tigris for now, let's store a copy of the congressional districts in our project so we can easily re-use the sf object

Let's create a new folder called 'data' to store the shapefiles.. and now let's also save this script as 'obtain-cd-shapefiles.R'

... and now we export our shapefiles with 

us_cd_20m %>%
  write_sf("data/us-congressional-districts/us-congressional-districts.shp")
  
Oh! We get an error! That's because write_sf() isn't allowed to create new folders, so let's manually do that 

New Folder > congressional-districts

Okay! So our shapefiles have been succesfully exported and can be read in again with read_sf().

---

## {tidycensus}

{tidycensus} provides programmatic access to two data sources:

.pull-left[
The [Decennial US Census](https://www.census.gov/programs-surveys/decennial-census/data.html) which currently includes data for 1990, 2000 and 2010.

```{r}
get_decennial(geography = "county",
              variables = "P005004", 
              state = "VT")
```
]

--

.pull-right[

The [5-year American Community Survey](https://www.census.gov/programs-surveys/acs) (ACS) which currently includes data for 2009 through 2018.

```{r}
get_acs(geography = "county", 
        variables = "B19013_001", 
        state = "VT")
```

]

???

Let's switch to looking at the second package I mentioned at the beginning - {tidycensus}.

This provides programmatic access to two data sources:

- The first is the Decennial US census which currently includes data for 1990, 2000 and 2010... because the {tidycensus} package uses the US Census Bureau's API you can rest assured that future censuses will be included as well


- The second data source is the 5-year American Community Survey (ACS) which currently includes data for each survey between 2009 and 2018 - this too will provide access to future surveys once the data has been collected.

Because both datasets are very differently structured there's a distinct function for each - get_decennial for the actual census and get_acs() for the 5 year ACS survey.

---

##  {tidycensus} API

Before we can use the `{tidycensus}` package we must register for a **free** API key from the census bureau by following this workflow:

--

1\. Obtain a key from the signup page: [api.census.gov/data/key_signup.html](http://api.census.gov/data/key_signup.html)

--

2\. Check your email and click on the **activate your key** link

> You've attempted to validate an unknown key. If it has been more than 48 hours since you submitted your request for this API key then the request has been removed from the system. Please request a new key and activate it within 48 hours.

--

3\. Add your Census API key to your `.Renviron` using `census_api_key()` 

```{r}
census_api_key("your-key", install = TRUE)
```


???

Before we can use the {tidycensus} package we need to register for the FREE Census Bureua API. 

In the previous video about geocoding services I talked about free usage and how you might need to pay for those APIs... pretty much all use cases of the census APIs are free, but you can get in touch with them if you're concerned you're going to use it extremely heavily.

Let's go through the workflow we need to follow to use the API

First - we need to visit the signup page and provide our organisation name and email...

your organisation can be whatever you like, for this video I'm going to go for Charlie at R for the Rest of Us ... and I'm going to use a trick to get a new key to my email addresss:

charlie+censusapi@visibledata.co.uk

The next step is to wait for an email to come through with your API key... David is going to do some editing magic to make this look instantaneous but I'm going to wait for 5 miutes... so my API key has come through but we **must** click on the activate link for it to work... there's a chance that you'll get an error message saying you're tried to validate an unknown key, wait a few minutes and then try again.

When that's gone through successfully we need to register our API key with R.

Let's jump back into RStusio and create a new script called `tidycensus-notes.R`

We'll load our packages:

library(tidyverse)
library(tidycensus)
library(mapview)

Now in the console let's write 

census_api_key()

and paste our key into the first argument

... to make this work automagically in future we'll set install = TRUE which will store our API key in the .REnviron file - check out the Learn more section of this page if you want to understand more about how this works.

---

## Searching for census variables

`{tidycensus}` uses **variable codes** to access data from the API.

> Use `load_variable()` to find the variable code for the data you're interested in.

--

The process varies for the Census and ACS datasets:

.pull-left[

Use `dataset = "sf1"` for **Decennial Census** data.

```{r}
vars_census_2010 <- 
  load_variables(2010,
                 dataset = "sf1")
```


]

.pull-right[

Use `dataset = "acs5"` for **ACS** data.

```{r}
vars_acs_2010 <- 
  load_variables(2018,
                 dataset = "acs5")
```

]


???

Okay! We're almost at the point that we can obtain data from tidycensus - there's one last thing we need to deal with.

To access data from the API you need to find the variable code for the information you're interested in. 

We use the load_variable() function to obtain a labelled table of variables for each dataset.

The process varies between the Census and ACS datasets:

for data from the Decennial census you should set the dataset argument as "sf1" and for data from the ACS surveys you should set the dataset as "acs5"... there's a little bit more about this in the Learn more section for this page.

---

## (RStudio Coding Slide)

Okay! Let's go and search through the census variables for the total population of each region.

vars_census_2010 <- load_variables(2010, dataset = "sf1")

Let's use the View() function to explore the variables

View(vars_census_2010)

Let's type into the search field total population ... and here we've got our code: P001001

Now we can use get_decennial() to extract this property:

get_decennial(geography = "state", variables = "P001001"

This returns us a tibble with the total population per geographic unit - State in this case!

The {tidycensus} allows us to directly obtain the shapes using the geometry argument - which actually ends up using the tigris package I mentioned earlier.

get_decennial(geography = "state", variables = "P001001", geometry = TRUE)

That's the very basics of using tidycensus - but let's do something more complex.



---

class: my-turn

## My Turn

.pull-left[

I'm going to compare the fraction of rented properties across congressional districts by combining `{tidycensus}` and `{tigris}`.

]

.pull-right[

```{r, eval=TRUE, echo=FALSE, out.height="400px"}
us_cd_20m <- read_sf("data/us-congressional-districts")

tenure_cd_census_2010 <- read_csv("data/tenure_cd_census_2010.csv")

us_cd_20m %>%
  left_join(tenure_cd_census_2010) %>%
  filter(!STATEFP %in% c("02", "72", "15")) %>%
  mapview(zcol = "rented_fraction")
```

]

---

## (RStudio Coding Slide)

???

Okay! We need to go and find the appropriate variables:

vars_census_2010 %>%
  View()
  
There's a concept called "TENURE" that contains the variables we need, let's setup our get_decennial() function to get data for each congressional district

```{r}
tenure_cd_census_2010 <- get_decennial(geography = "congressional district", 
                                       variables = , 
                                       year = 2010)
```

Now we'll create a vector for our variables with c()

and copy and paste the variables from the view tab 

```{r}
tenure_cd_census_2010 <- get_decennial(geography = "congressional district", 
                                       variables = c("H004002", "H004003", "H004004"), 
                                       year = 2010)
```

Now, the data that we've returned is long formatted - because the tidycensus package makes use of the tidy data concept. But, we need to calculate the fraction of households in each congressional district that are rented - which means we'll need to convert the data into wide format with pivot_wider()

... you might be familiar with using the spread() function instead, this has been deprecated since 2019 in favour of the much more powerful pivot_wider() function... but spread() is not going anywhere, so if you still want to use it that's fine.

```{r}
tenure_cd_census_2010 %>%
  pivot_wider(names_from = variable,
              values_from = value)
```

Okay!

Now let's also rename the variable columns:

```{r}
tenure_cd_census_2010 %>%
  pivot_wider(names_from = variable,
              values_from = value) %>% 
  rename(mortgage_or_loan = H004002,
         owned_outright = H004003,
         rented = H004004)
```

And finally we can use mutate to add a column that calculates the fraction of rented properties!

```{r}
tenure_cd_census_2010 <- tenure_cd_census_2010 %>%
  pivot_wider(names_from = variable,
              values_from = value) %>%
  rename(mortgage_or_loan = H004002,
         owned_outright = H004003,
         rented = H004004) %>%
  mutate(rented_fraction = rented / {mortgage_or_loan + owned_outright + rented})
```

Now we've done that let's join it with the shapefiles that we previously obtained from tigris.

```{r}
us_cd_20m <- read_sf("data/us-congressional-districts")
```

```{r}
us_cd_sf %>%
  left_join(tenure_cd_census_2010,
            by = "GEOID") %>%
  mapview(zcol = "rented_percent")
```

... you might've noted in my slide the map only showed the contigious US, we can filter out the non-contiguous US with this handly line:

```{r}
us_cd_sf %>%
  left_join(tenure_cd_census_2010,
            by = "GEOID") %>%
  # filter(!STATEFP %in% c("02", "72", "15")) %>%
  mapview(zcol = "rented_percent")
```

---

class: inverse

### Your Turn

.pull-left[
1. Use `load_variables()` to find the **Renter Occupied variables for each age bracket** in the 2010 Decennial Census.

1. Use `get_decennial()` to extract all of the 9 variables from above

1. Use `pivot_wider()` to prepare the data for joining with the congressional district shapefiles.

1. Join the Census and shapefiles datasets with `left_join()` and visualise with `mapview()`
]

.pull-right[

```{r, eval=TRUE, echo=FALSE, out.height="400px"}
age_cd_census_2010 <- read_csv("data/age_cd_census_2010.csv")

us_cd_20m %>%
  left_join(age_cd_census_2010) %>%
  filter(!STATEFP %in% c("02", "72", "15")) %>%
  mapview(zcol = "age_85_plus")
```

]

???

Okay! For your turn I'd like you to go through the same process, this time look through the census variables for the total number of rental occupants in each age bracket for the 2010 Decennial Census. You should find a total of 9 variable codes which you'll then have to obtain and join together with the congressional district shapefiles we downloaded earlier in this video.

